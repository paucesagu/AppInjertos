{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2eee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos lo 3 métodos que utilizaremos\n",
    "from flask import Flask, request, jsonify\n",
    "from flask import *\n",
    "from waitress import serve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from copy import copy\n",
    "import csv as csv\n",
    "\n",
    "# Clasificación\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import tree\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#exportar modelo\n",
    "import joblib\n",
    "\n",
    "#TPOT\n",
    "#from tpot import TPOTClassifier\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "# Evaluación\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,precision_recall_fscore_support, f1_score, roc_curve, roc_auc_score,auc, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, LeaveOneOut\n",
    "\n",
    "#preprocesamiento\n",
    "from sklearn.preprocessing import FunctionTransformer, Normalizer, RobustScaler, StandardScaler\n",
    "\n",
    "# selección de atributos\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, chi2\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, SelectFromModel, VarianceThreshold\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#para reentrenar\n",
    "import time\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6ec2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "182600aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos =  pd.read_csv('datos_one_hot.csv')\n",
    "datos = datos.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f39bc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nos conectamos a la base de datos mysql y añadimos la fila cuyo indice sea mayor al dado por parámetro para no añadir todas las de la bd y evitar que esten repetidas\n",
    "def añadirInstancias(indice):\n",
    "    \n",
    "    conexion1=mysql.connector.connect(host='127.0.0.1',\n",
    "        user='root',\n",
    "        password='password',\n",
    "        database='injertosdb',\n",
    "        port=3306) \n",
    "    ultIndice = 0\n",
    "    print(\"hace la conexion con la base de datos\")\n",
    "    cursor1=conexion1.cursor()\n",
    "    sentencia = \"SELECT id, edad, sexo, imc, hta, dm, dlp, apm, apq, got, gpt, ggt, na,bbt, acvhc, acvhbc, dosisna, aminas, validez, ecografia_1, ecografia_2, ecografia_3 FROM injertos i LEFT OUTER JOIN valoraciones v ON  v.id_injerto = i.id where id>\" + str(indice)\n",
    "    print(\"obtenemos datos de las instancias cuyo indice sea mayor al dado por parametro\")\n",
    "    #tenemos que guardar por que indice nos hemos quedado\n",
    "    cursor1.execute(sentencia)\n",
    "    for fila in cursor1:\n",
    "        ultIndice = fila[0]\n",
    "        datos.loc[len(datos)] = list(fila)[1:]\n",
    "    conexion1.close()\n",
    "    print(\"guardamos las instancias en un nuevo dataset\")\n",
    "    datos.to_csv('datos_one_hot.csv') #actualizamos el dataset con las nuevas instancias\n",
    "    return (ultIndice, len(datos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d66ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hace la conexion con la base de datos\n",
      "obtenemos datos de las instancias cuyo indice sea mayor al dado por parametro\n",
      "guardamos las instancias en un nuevo dataset\n",
      "ya ha dividido el modelo\n",
      "     Edad  Sexo        IMC  HTA   DM  DLP  APM  APQ   GOT   GPT        GGT  \\\n",
      "0    21.0   0.0  28.890000  0.0  0.0  0.0  1.0  0.0  45.0  95.0  300.00000   \n",
      "1    79.0   0.0  31.250000  1.0  0.0  0.0  1.0  1.0  23.0  17.0   18.00000   \n",
      "2    77.0   1.0  28.410000  1.0  1.0  1.0  1.0  0.0  12.0  10.0   36.00000   \n",
      "3    80.0   0.0  23.440000  1.0  0.0  1.0  1.0  0.0  54.0  17.0   11.00000   \n",
      "4    49.0   1.0  27.700000  0.0  0.0  0.0  1.0  0.0  56.0  85.0   83.15811   \n",
      "..    ...   ...        ...  ...  ...  ...  ...  ...   ...   ...        ...   \n",
      "399  76.0   0.0  32.500000  1.0  1.0  0.0  1.0  0.0  22.0  52.0   62.00000   \n",
      "400  74.0   0.0  28.597929  0.0  0.0  0.0  1.0  0.0  36.0  56.0   55.00000   \n",
      "401  63.0   1.0  24.490000  0.0  0.0  0.0  1.0  0.0  15.0  18.0   43.00000   \n",
      "402  65.0   1.0  28.340000  1.0  0.0  0.0  0.0  0.0  29.0  18.0   82.00000   \n",
      "403  81.0   0.0  32.810000  1.0  1.0  1.0  1.0  1.0  22.0  21.0   68.00000   \n",
      "\n",
      "        Na   BbT  AcVHC  AcVHBc  DosisNA  Aminas  Ecografia_1  Ecografia_2  \\\n",
      "0    149.0  0.32    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "1    145.0  0.34    0.0     0.0     0.02     1.0          1.0          0.0   \n",
      "2    149.0  0.33    0.0     0.0     0.08     1.0          1.0          0.0   \n",
      "3    152.0  1.00    0.0     0.0     0.10     1.0          1.0          0.0   \n",
      "4    137.0  0.40    1.0     0.0     0.00     0.0          0.0          1.0   \n",
      "..     ...   ...    ...     ...      ...     ...          ...          ...   \n",
      "399  148.0  0.80    0.0     0.0     0.10     1.0          1.0          0.0   \n",
      "400  150.0  0.80    0.0     0.0     0.20     1.0          1.0          0.0   \n",
      "401  138.0  0.40    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "402  139.0  0.94    0.0     0.0     0.06     1.0          0.0          1.0   \n",
      "403  153.0  0.80    0.0     0.0     0.15     1.0          1.0          0.0   \n",
      "\n",
      "     Ecografia_3  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "..           ...  \n",
      "399          0.0  \n",
      "400          0.0  \n",
      "401          0.0  \n",
      "402          0.0  \n",
      "403          0.0  \n",
      "\n",
      "[404 rows x 20 columns]\n",
      "     Edad  Sexo        IMC  HTA   DM  DLP  APM  APQ   GOT   GPT        GGT  \\\n",
      "0    21.0   0.0  28.890000  0.0  0.0  0.0  1.0  0.0  45.0  95.0  300.00000   \n",
      "1    79.0   0.0  31.250000  1.0  0.0  0.0  1.0  1.0  23.0  17.0   18.00000   \n",
      "2    77.0   1.0  28.410000  1.0  1.0  1.0  1.0  0.0  12.0  10.0   36.00000   \n",
      "3    80.0   0.0  23.440000  1.0  0.0  1.0  1.0  0.0  54.0  17.0   11.00000   \n",
      "4    49.0   1.0  27.700000  0.0  0.0  0.0  1.0  0.0  56.0  85.0   83.15811   \n",
      "..    ...   ...        ...  ...  ...  ...  ...  ...   ...   ...        ...   \n",
      "399  76.0   0.0  32.500000  1.0  1.0  0.0  1.0  0.0  22.0  52.0   62.00000   \n",
      "400  74.0   0.0  28.597929  0.0  0.0  0.0  1.0  0.0  36.0  56.0   55.00000   \n",
      "401  63.0   1.0  24.490000  0.0  0.0  0.0  1.0  0.0  15.0  18.0   43.00000   \n",
      "402  65.0   1.0  28.340000  1.0  0.0  0.0  0.0  0.0  29.0  18.0   82.00000   \n",
      "403  81.0   0.0  32.810000  1.0  1.0  1.0  1.0  1.0  22.0  21.0   68.00000   \n",
      "\n",
      "        Na   BbT  AcVHC  AcVHBc  DosisNA  Aminas  Ecografia_1  Ecografia_2  \\\n",
      "0    149.0  0.32    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "1    145.0  0.34    0.0     0.0     0.02     1.0          1.0          0.0   \n",
      "2    149.0  0.33    0.0     0.0     0.08     1.0          1.0          0.0   \n",
      "3    152.0  1.00    0.0     0.0     0.10     1.0          1.0          0.0   \n",
      "4    137.0  0.40    1.0     0.0     0.00     0.0          0.0          1.0   \n",
      "..     ...   ...    ...     ...      ...     ...          ...          ...   \n",
      "399  148.0  0.80    0.0     0.0     0.10     1.0          1.0          0.0   \n",
      "400  150.0  0.80    0.0     0.0     0.20     1.0          1.0          0.0   \n",
      "401  138.0  0.40    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "402  139.0  0.94    0.0     0.0     0.06     1.0          0.0          1.0   \n",
      "403  153.0  0.80    0.0     0.0     0.15     1.0          1.0          0.0   \n",
      "\n",
      "     Ecografia_3  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "..           ...  \n",
      "399          0.0  \n",
      "400          0.0  \n",
      "401          0.0  \n",
      "402          0.0  \n",
      "403          0.0  \n",
      "\n",
      "[404 rows x 20 columns]\n",
      "acaba\n",
      "4\n",
      "hace la conexion con la base de datos\n",
      "obtenemos datos de las instancias cuyo indice sea mayor al dado por parametro\n",
      "guardamos las instancias en un nuevo dataset\n",
      "ya ha dividido el modelo\n",
      "     Edad  Sexo        IMC  HTA   DM  DLP  APM  APQ   GOT   GPT        GGT  \\\n",
      "0    21.0   0.0  28.890000  0.0  0.0  0.0  1.0  0.0  45.0  95.0  300.00000   \n",
      "1    79.0   0.0  31.250000  1.0  0.0  0.0  1.0  1.0  23.0  17.0   18.00000   \n",
      "2    77.0   1.0  28.410000  1.0  1.0  1.0  1.0  0.0  12.0  10.0   36.00000   \n",
      "3    80.0   0.0  23.440000  1.0  0.0  1.0  1.0  0.0  54.0  17.0   11.00000   \n",
      "4    49.0   1.0  27.700000  0.0  0.0  0.0  1.0  0.0  56.0  85.0   83.15811   \n",
      "..    ...   ...        ...  ...  ...  ...  ...  ...   ...   ...        ...   \n",
      "400  74.0   0.0  28.597929  0.0  0.0  0.0  1.0  0.0  36.0  56.0   55.00000   \n",
      "401  63.0   1.0  24.490000  0.0  0.0  0.0  1.0  0.0  15.0  18.0   43.00000   \n",
      "402  65.0   1.0  28.340000  1.0  0.0  0.0  0.0  0.0  29.0  18.0   82.00000   \n",
      "403  81.0   0.0  32.810000  1.0  1.0  1.0  1.0  1.0  22.0  21.0   68.00000   \n",
      "404  65.0   0.0  25.810000  1.0  1.0  1.0  1.0  1.0  22.0  21.0   68.00000   \n",
      "\n",
      "        Na   BbT  AcVHC  AcVHBc  DosisNA  Aminas  Ecografia_1  Ecografia_2  \\\n",
      "0    149.0  0.32    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "1    145.0  0.34    0.0     0.0     0.02     1.0          1.0          0.0   \n",
      "2    149.0  0.33    0.0     0.0     0.08     1.0          1.0          0.0   \n",
      "3    152.0  1.00    0.0     0.0     0.10     1.0          1.0          0.0   \n",
      "4    137.0  0.40    1.0     0.0     0.00     0.0          0.0          1.0   \n",
      "..     ...   ...    ...     ...      ...     ...          ...          ...   \n",
      "400  150.0  0.80    0.0     0.0     0.20     1.0          1.0          0.0   \n",
      "401  138.0  0.40    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "402  139.0  0.94    0.0     0.0     0.06     1.0          0.0          1.0   \n",
      "403  153.0  0.80    0.0     0.0     0.15     1.0          1.0          0.0   \n",
      "404  153.0  0.80    1.0     0.0     0.15     1.0          1.0          0.0   \n",
      "\n",
      "     Ecografia_3  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "..           ...  \n",
      "400          0.0  \n",
      "401          0.0  \n",
      "402          0.0  \n",
      "403          0.0  \n",
      "404          0.0  \n",
      "\n",
      "[405 rows x 20 columns]\n",
      "     Edad  Sexo        IMC  HTA   DM  DLP  APM  APQ   GOT   GPT        GGT  \\\n",
      "0    21.0   0.0  28.890000  0.0  0.0  0.0  1.0  0.0  45.0  95.0  300.00000   \n",
      "1    79.0   0.0  31.250000  1.0  0.0  0.0  1.0  1.0  23.0  17.0   18.00000   \n",
      "2    77.0   1.0  28.410000  1.0  1.0  1.0  1.0  0.0  12.0  10.0   36.00000   \n",
      "3    80.0   0.0  23.440000  1.0  0.0  1.0  1.0  0.0  54.0  17.0   11.00000   \n",
      "4    49.0   1.0  27.700000  0.0  0.0  0.0  1.0  0.0  56.0  85.0   83.15811   \n",
      "..    ...   ...        ...  ...  ...  ...  ...  ...   ...   ...        ...   \n",
      "400  74.0   0.0  28.597929  0.0  0.0  0.0  1.0  0.0  36.0  56.0   55.00000   \n",
      "401  63.0   1.0  24.490000  0.0  0.0  0.0  1.0  0.0  15.0  18.0   43.00000   \n",
      "402  65.0   1.0  28.340000  1.0  0.0  0.0  0.0  0.0  29.0  18.0   82.00000   \n",
      "403  81.0   0.0  32.810000  1.0  1.0  1.0  1.0  1.0  22.0  21.0   68.00000   \n",
      "404  65.0   0.0  25.810000  1.0  1.0  1.0  1.0  1.0  22.0  21.0   68.00000   \n",
      "\n",
      "        Na   BbT  AcVHC  AcVHBc  DosisNA  Aminas  Ecografia_1  Ecografia_2  \\\n",
      "0    149.0  0.32    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "1    145.0  0.34    0.0     0.0     0.02     1.0          1.0          0.0   \n",
      "2    149.0  0.33    0.0     0.0     0.08     1.0          1.0          0.0   \n",
      "3    152.0  1.00    0.0     0.0     0.10     1.0          1.0          0.0   \n",
      "4    137.0  0.40    1.0     0.0     0.00     0.0          0.0          1.0   \n",
      "..     ...   ...    ...     ...      ...     ...          ...          ...   \n",
      "400  150.0  0.80    0.0     0.0     0.20     1.0          1.0          0.0   \n",
      "401  138.0  0.40    0.0     0.0     0.00     0.0          1.0          0.0   \n",
      "402  139.0  0.94    0.0     0.0     0.06     1.0          0.0          1.0   \n",
      "403  153.0  0.80    0.0     0.0     0.15     1.0          1.0          0.0   \n",
      "404  153.0  0.80    1.0     0.0     0.15     1.0          1.0          0.0   \n",
      "\n",
      "     Ecografia_3  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "..           ...  \n",
      "400          0.0  \n",
      "401          0.0  \n",
      "402          0.0  \n",
      "403          0.0  \n",
      "404          0.0  \n",
      "\n",
      "[405 rows x 20 columns]\n",
      "acaba\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.secret_key = \"tfgPAU_GUI22\" #Secret Key\n",
    "\n",
    "# Load the model\n",
    "MODEL = joblib.load('./ValHepaticos-model.pkl')\n",
    "\n",
    "# Las etiquetas con las cuales se clasificaran nuevos datos\n",
    "\n",
    "MODEL_LABELS = [\"Valido\",\"No valido\"]\n",
    "\n",
    "\"\"\"\n",
    "El método predict sera el encargado de clasificar y dar una respuesta\n",
    "a cualquier IP que le envie una petición.\n",
    "\"\"\"\n",
    "\n",
    "@app.route('/predict')\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    Declaramos cuales seran los parametros que recibe la petición\n",
    "    \n",
    "    \"\"\"\n",
    "    edad = request.args.get('edad')\n",
    "    sexo = request.args.get('sexo')\n",
    "    imc = request.args.get('imc')\n",
    "    hta = request.args.get('hta')\n",
    "    dm = request.args.get('dm')\n",
    "    dlp = request.args.get('dlp')\n",
    "    apm = request.args.get('apm')\n",
    "    apq = request.args.get('apq')\n",
    "    got = request.args.get('got')\n",
    "    gpt = request.args.get('gpt')\n",
    "    ggt = request.args.get('ggt')\n",
    "    na = request.args.get('na')\n",
    "    bbt = request.args.get('bbt')\n",
    "    acvhc = request.args.get('acvhc')\n",
    "    acvhbc = request.args.get('acvhbc')\n",
    "    dosisna = request.args.get('dosisna')\n",
    "    aminas = request.args.get('aminas')\n",
    "    ecografia_1 = request.args.get('ecografia_1')\n",
    "    ecografia_2 = request.args.get('ecografia_2')\n",
    "    ecografia_3 = request.args.get('ecografia_3')\n",
    "\n",
    "\n",
    "    # La lista de caracteristicas que se utilizaran\n",
    "    # para la predicción\n",
    "    features = [[edad, sexo, imc, hta, dm, dlp, apm, apq, got, gpt, ggt, na, bbt, acvhc, acvhbc, dosisna, aminas,ecografia_1, ecografia_2, ecografia_3]]\n",
    "    \n",
    "    # Utilizamos el modelo para la predicción de los datos\n",
    "    label_index = MODEL.predict(features)\n",
    "    y_proba = MODEL.predict_proba(features)\n",
    "    \n",
    "    \"\"\"\n",
    "    La variable label contendra el resultado de la clasificación.\n",
    "    \"\"\"\n",
    "    label = MODEL_LABELS[label_index[0]]\n",
    "    prob = y_proba[0][label_index[0]]\n",
    "   \n",
    "    \n",
    "    # Creamos y enviamos la respuesta al cliente\n",
    "    return jsonify(status='clasificado completado', clasificacion=label, probabilidad = str(prob))\n",
    "\n",
    "\n",
    "@app.route(\"/reentrenar\")\n",
    "def reentrenar():\n",
    "    #declaramos los parametros que le vendran:\n",
    "    indice = request.args.get('indice') #reentrenaremos añadiendo a partir de ese índice\n",
    "    print(indice)\n",
    "    start = time.time()\n",
    "    ultIndice, numInstancias = añadirInstancias(indice)\n",
    "    #quitamos la clase del dataset, vamos a realizar 5-CV\n",
    "    y = datos['class']\n",
    "    X = datos.drop(['class'], axis=1)\n",
    "    #vamos a devolver el auc\n",
    "    print(\"ya ha dividido el modelo\")\n",
    "    print(X)\n",
    "    y_proba = cross_val_predict(MODEL, X, y, cv=5, method='predict_proba')\n",
    "    y_proba_clase1 =  pd.Series(y_proba[:,1])\n",
    "    print(X)\n",
    "    fprs, tprs, umbrales = metrics.roc_curve(y, y_proba_clase1)\n",
    "    auc = metrics.auc(fprs,tprs)\n",
    "    end = time.time()\n",
    "    tiempo = end-start\n",
    "    print(\"acaba\")\n",
    "    \n",
    "    return jsonify(status='reentrenado con exito', numeroInstancias=numInstancias, ultimaInstancia=ultIndice, valorAUC=auc, tiempoRequerido=tiempo)\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return \"<h1>Página del clasificador!</h1>\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Iniciamos el servidor\n",
    "    #context = ('./cert/cert2.pem', './cert/key2.pem') #Location of certificate & key\n",
    "    #app.run(port=4000, ssl_context=context) #Specify variable to run function\n",
    "    serve(app, listen='localhost:8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "99069511",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-3267c39eb883>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_proba_clase1\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[0msplits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, y, classifier)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         if (classifier and (y is not None) and\n\u001b[1;32m-> 2061\u001b[1;33m                 (type_of_target(y) in ('binary', 'multiclass'))):\n\u001b[0m\u001b[0;32m   2062\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'f'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y = datos['class']\n",
    "X = datos.drop(['class'], axis=1)\n",
    "y_proba = cross_val_predict(MODEL, X, y, cv=5, method='predict_proba')\n",
    "y_proba_clase1 =  pd.Series(y_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "296eb79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      1.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "      ... \n",
       "419    NaN\n",
       "420    NaN\n",
       "421    NaN\n",
       "422    NaN\n",
       "423    1.0\n",
       "Name: class, Length: 424, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
